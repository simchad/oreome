{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment (2023.01.18.)\n",
    "\n",
    "# .py & .ipynb 차이점\n",
    "# - MQpy/old_notebooks/pg_03_3_processing.ipynb 에서 시작.\n",
    "# - 복붙 x. 타이핑 해가며 기억 깨우기...!\n",
    "# - directory 달라져서 변경해야함. raw_files 폴더 위치 파일 사용하기.\n",
    "# .py 일 경우, 파이썬 패키지 설치하기 위해서 환경변수 설정해야. 파이썬 설치해야.\n",
    "# .ipynb 일 경우, 기본 탑재.\n",
    "\n",
    "\n",
    "# Scope\n",
    "\n",
    "# - proteinGroups.txt 로드 후 다음의 column data를 필터함.\n",
    "# : contaminants, reverse, only identified site, uniquepeptide = 1 entries\n",
    "# - protein names, Best MS/MS 항목에서 세미콜론(;) 구분된 데이터 요소를 split.\n",
    "# - filter가 된 것을 *_base.xlsx 로 저장함.\n",
    "\n",
    "\n",
    "# Uniprot API\n",
    "\n",
    "# - IdMapping: https://uniprot.org/help/id_mapping 참조\n",
    "\n",
    "\n",
    "# proteinGroups.txt 의 Dtype\n",
    "\n",
    "# - object(delimeter), int64, float64\n",
    "\n",
    "\n",
    "# vscode 터미널에서 pip 안될때\n",
    "\n",
    "# 원인: python 옳게 설치했더라도 윈도우 클래스에서 pip 위치를 알지 못하기에 발생.\n",
    "# python3 부터는 pip 내장이므로 python.exe 디렉터리 연결하면 됨.\n",
    "# C:\\Users\\Simon\\AppData\\Local\\Programs\\Python\\Python39\\Scipts 를 다음에 추가하면됨.\n",
    "# (고급 시스템 설정 보기) - (환경변수 탭) - (사용자에 대한 사용자 변수 및 시스템 변수의 path에 추가)\n",
    "\n",
    "\n",
    "# 아나콘다 업데이트\n",
    "# conda update -n base conda <-- base 업데이트\n",
    "# conda update --all <-- 패키지 업데이트\n",
    "# python -m pip install --upgrade pip <-- pip 패키지 업데이트\n",
    "# conda --version <-- version 확인\n",
    "\n",
    "\n",
    "# 다른 설정들\n",
    "# 셀 라인 표시 shift + L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message! >>> 11 (0.92%) entries were dropped, [Potential contaminant] column removed.\n",
      "message! >>> 12 (1.01%) entries were dropped, [Reverse] column removed.\n",
      "message! >>> 25 (2.13%) entries were dropped, [Only identified by site] column removed.\n",
      "message! >>> 385 (33.60%) entries were dropped. [Razor + unique peptides = 1]\n",
      "message! >>> 761 entries left.\n",
      "message! >>> [Protein IDs] elements were splitted\n",
      "message! >>> [Best MS/MS] elements were splitted\n"
     ]
    }
   ],
   "source": [
    "# Neccessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('C:/Users/simhc/Documents/Github/proteome-tool/')\n",
    "\n",
    "# Base_filter를 사용할 txt 베이스 raw 파일을 로드합니다.\n",
    "global txtpath\n",
    "txtpath = './raw/TestSample/QC_DU145/proteinGroups.txt'\n",
    "\n",
    "# **kwargs 인수로 받는 함수... 클래스에 들어가면 init 잘 해야.\n",
    "def isDrop(**kwargs):\n",
    "    # **kwargs: keyword argument 줄임말. 인수를 딕셔너리로 받음.\n",
    "    for key, value in kwargs.items():\n",
    "        tmp1 = len(df)\n",
    "        tmp2 = len(df[df[key] == value])\n",
    "        ratio = (100*tmp2)/tmp1\n",
    "        # key에 해당하는 value를 가진 entry 드랍.\n",
    "        df.drop(df[df[key] == value].index, inplace=True)\n",
    "        # value가 숫자인 경우: column 드랍하지 않음.\n",
    "        # e.g., Razor + unique peptides의 경우, value = 1 인 entry 드랍 하지만, 나머지 entry는 남아야하므로.\n",
    "        if isinstance(value, str):\n",
    "            df.drop(columns=[key], inplace=True)\n",
    "            print('message! >>> '+str(tmp2)+' (%.2f%%) entries were dropped, [' %ratio +key+'] column removed.')\n",
    "        else:\n",
    "            print('message! >>> '+str(tmp2)+' (%.2f%%) entries were dropped. ['%ratio +key+' = '+str(value)+']')\n",
    "            # print('message! >>> '+str(tmp2)+' (%.2f%%) entries were dropped, ['+key+'] column removed' %ratio) <- 이 구문은 동작안함. %~~ 이게 string으로 나눈 같은 구역에 있어햐 함.\n",
    "    return print('message! >>> '+str(len(df))+' entries left.')\n",
    "\n",
    "# Split할 column 이름을 tuple (c1, c2)로 주고, delimeter의 기본값은 세미콜론(;)으로 되어있다.\n",
    "def split_items(*args, delimeter=';'):\n",
    "    for arg in args:\n",
    "        tmp_series = pd.Series(df[arg])\n",
    "        for ele in tmp_series:\n",
    "            tmp = ele.split(delimeter)[0]\n",
    "            tmp_series.replace(ele, tmp, inplace=True)\n",
    "        print('message! >>> ['+arg+'] elements were splitted')\n",
    "    return None\n",
    "    # return df.head\n",
    "\n",
    "def execute(drop_rule, split_cnames):\n",
    "    # read txt file.\n",
    "    isDrop(**drop_rule)\n",
    "    split_items(*split_cnames)\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_table(filepath_or_buffer=txtpath, index_col=False)\n",
    "    base_filter = {'Potential contaminant':'+', 'Reverse':'+', 'Only identified by site':'+', 'Razor + unique peptides':1}\n",
    "    split_cnames = ('Protein IDs', 'Best MS/MS')\n",
    "    execute(base_filter, split_cnames)\n",
    "\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 3s\n",
      "Retrying in 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Gene Names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ESYT2_HUMAN</td>\n",
       "      <td>Extended synaptotagmin-2 (E-Syt2) (Chr2Syt)</td>\n",
       "      <td>ESYT2 FAM62B KIAA1228</td>\n",
       "      <td>921</td>\n",
       "      <td>MTANRDAALSSHRHPGCAQRPRTPTFASSSQRRSAFGFDDGNFPGL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6NHR9</td>\n",
       "      <td>A6NHR9</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>SMHD1_HUMAN</td>\n",
       "      <td>Structural maintenance of chromosomes flexible...</td>\n",
       "      <td>SMCHD1 KIAA0650</td>\n",
       "      <td>2005</td>\n",
       "      <td>MAAADGGGPGGASVGTEEDGGGVGHRTVYLFDRREKESELGDRPLQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q99613</td>\n",
       "      <td>Q99613</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>EIF3C_HUMAN</td>\n",
       "      <td>Eukaryotic translation initiation factor 3 sub...</td>\n",
       "      <td>EIF3C EIF3S8</td>\n",
       "      <td>913</td>\n",
       "      <td>MSRFFTTGSDSESESSLSGEELVTKPVGGNYGKQPLLLSEDEEDTK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E9PAV3</td>\n",
       "      <td>E9PAV3</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>NACAM_HUMAN</td>\n",
       "      <td>Nascent polypeptide-associated complex subunit...</td>\n",
       "      <td>NACA</td>\n",
       "      <td>2078</td>\n",
       "      <td>MPGEATETVPATEQELPQPQAETAVLPMSSALSVTAALGQPGPTLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O00148</td>\n",
       "      <td>O00148</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>DX39A_HUMAN</td>\n",
       "      <td>ATP-dependent RNA helicase DDX39A (EC 3.6.4.13...</td>\n",
       "      <td>DDX39A DDX39</td>\n",
       "      <td>427</td>\n",
       "      <td>MAEQDVENDLLDYDEEEEPQAPQESTPAPPKKDIKGSYVSIHSSGF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     From   Entry  Reviewed   Entry Name  \\\n",
       "0  A0FGR8  A0FGR8  reviewed  ESYT2_HUMAN   \n",
       "1  A6NHR9  A6NHR9  reviewed  SMHD1_HUMAN   \n",
       "2  Q99613  Q99613  reviewed  EIF3C_HUMAN   \n",
       "3  E9PAV3  E9PAV3  reviewed  NACAM_HUMAN   \n",
       "4  O00148  O00148  reviewed  DX39A_HUMAN   \n",
       "\n",
       "                                       Protein names             Gene Names  \\\n",
       "0        Extended synaptotagmin-2 (E-Syt2) (Chr2Syt)  ESYT2 FAM62B KIAA1228   \n",
       "1  Structural maintenance of chromosomes flexible...        SMCHD1 KIAA0650   \n",
       "2  Eukaryotic translation initiation factor 3 sub...           EIF3C EIF3S8   \n",
       "3  Nascent polypeptide-associated complex subunit...                   NACA   \n",
       "4  ATP-dependent RNA helicase DDX39A (EC 3.6.4.13...           DDX39A DDX39   \n",
       "\n",
       "  Length                                           Sequence  \n",
       "0    921  MTANRDAALSSHRHPGCAQRPRTPTFASSSQRRSAFGFDDGNFPGL...  \n",
       "1   2005  MAAADGGGPGGASVGTEEDGGGVGHRTVYLFDRREKESELGDRPLQ...  \n",
       "2    913  MSRFFTTGSDSESESSLSGEELVTKPVGGNYGKQPLLLSEDEEDTK...  \n",
       "3   2078  MPGEATETVPATEQELPQPQAETAVLPMSSALSVTAALGQPGPTLP...  \n",
       "4    427  MAEQDVENDLLDYDEEEEPQAPQESTPAPPKKDIKGSYVSIHSSGF...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requests module 사용하여 web request-repond 프로세스를 수행합니다.\n",
    "# uniprot accession 형식의 Protein IDs 를 Uniprot ID Mapping에 요청-응답 수행.\n",
    "# 데이터프레임의 protein/gene name 및 sequence 등 항목을 수정해야 합니다.\n",
    "\n",
    "# 참고페이지\n",
    "# Uniprot API Help\n",
    "\n",
    "import csv\n",
    "from jobs.api_requests import uniprot_requests as unireq\n",
    "\n",
    "\n",
    "def get_data_frame_from_tsv_results(tsv_results):\n",
    "    reader = csv.DictReader(tsv_results, delimiter=\"\\t\", quotechar='\"')\n",
    "    return pd.DataFrame(list(reader))\n",
    "\n",
    "\n",
    "\n",
    "# 판다스로 데이터프레임의 컬럼 데이터 뽑아냅니다.\n",
    "# 테스트를 위하여 데이터의 일부를 새로운 객체 idSeries에 할당합니다.\n",
    "PRids = pd.Series(df['Protein IDs'])\n",
    "PRids2 = PRids[:6]\n",
    "\n",
    "\n",
    "\n",
    "# 테스트 데이터가 담긴 객체를 uniprot_request.py 모듈의 execute 메소드 호출 및 링크 받아옵니다.\n",
    "link = unireq.execute(PRids2)\n",
    "\n",
    "# link 통해 나온 결과는 stream.. 말그대로 텍스트의 엄청난 스트림!!\n",
    "# 같은 모듈의 get_id_mapping_results_stream 함수로 이 텍스트를 디코딩해서 필요한 부분을 추출합니다.\n",
    "#\n",
    "# ?compressed= true/false 는 다운로드 할 때 상관 있어서 차이는 없는 것으로 보임.\n",
    "# 추출: %2C[식별자] (e.g., %2Crequest, %2Cprotein_name, %2Cgene_name 등등.) 의 규칙으로 추출해서\n",
    "# 결과: &format=[확장자] (e.g., ~~&format=tsv) 로 결과물 만듦. delimeter 사용해서 데이터프레임 만든다.\n",
    "\n",
    "tsv_rst = unireq.get_id_mapping_results_stream(str(link)+'?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Clength%2Csequence&format=tsv')\n",
    "tmp = get_data_frame_from_tsv_results(tsv_rst)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://rest.uniprot.org/idmapping/uniprotkb/results/ebd732214f1fa3b46504d64ad8382cb1b37a2cf0\n"
     ]
    }
   ],
   "source": [
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniprot respond 데이터로 Protein names, Gene Names 교체할 수 있다.\n",
    "# 엑셀작업시 순서대로 였으면 순서대로 해도 되지만\n",
    "# 혹시 순서가 달라졌을수도 있으므로 From 값을 기준으로 replace를 수행할 것.\n",
    "\n",
    "# (1) protein names replace\n",
    "# 이건 거의 교차검증. 연산 너무 많다. (미완성)\n",
    "\n",
    "def prot_name_replace_1():\n",
    "    tmp_names = pd.Series(tmp['Protein names'])\n",
    "\n",
    "    prot_ids = pd.Series(df['Protein IDs'])\n",
    "    prot_names = pd.Seires(df['Protein names'])\n",
    "    return None\n",
    "\n",
    "# (2) 순서 같다는 것이 확실하면 column replace or append\n",
    "# 별일 없으면 순서는 같다. 단, indicies 일치해야.\n",
    "def prot_name_replace_2():\n",
    "    df['Protein names'] = tmp['Protein names']\n",
    "    df['Gene names'] = tmp['Gene Names']\n",
    "\n",
    "    return df\n",
    "\n",
    "tmp = prot_name_replace_2()\n",
    "tmp.head\n",
    "\n",
    "# prot_name_replace_2().head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 위로 완료.\n",
    "\n",
    "# 필요한 열만 추출해서 output 만들기 (2023.01.19.)\n",
    "# *.xlsx\n",
    "\n",
    "# 현재 df에 속하는 column 이름들 list로 저장.\n",
    "now_df_columns = list(df)\n",
    "print(now_df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "s = os.getcwd()\n",
    "\n",
    "print(os.getcwd().replace('jobs',''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남겨놓을 column label 제외 필터링.\n",
    "# 일반적인 base 파일에서 rough하게 이정도면 충분. (free TMT&SILAC. For only QC samples)\n",
    "\n",
    "# (고급) 단백질에 해당하는 펩타이드 sequence 가 gene에서 시작 위치가 어디인지.\n",
    "# Peptide IDs로 부터 peptides.txt 연계 해야.\n",
    "\n",
    "# 전체 columns 불러와서\n",
    "# *args 로 만들고 기본값은 None으로 해둔 뒤\n",
    "# 남길 column을 추가해놓으면 완성.\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import localtime, strftime\n",
    "\n",
    "rest = ['Protein IDs',\n",
    "        'Protein names',\n",
    "        'Gene names',\n",
    "        'Razor + unique peptides',\n",
    "        'Unique sequence coverage [%]',\n",
    "        'Mol. weight [kDa]',\n",
    "        'Sequence length',\n",
    "        'Q-value',\n",
    "        'Score',\n",
    "        'Intensity',\n",
    "        'id',\n",
    "        'Peptide IDs',\n",
    "        'Evidence IDs',\n",
    "        'Best MS/MS']\n",
    "\n",
    "# now_df_columns 안의 ele 들 중 ele에 대해서 if ele가 rest에 없는 것에 대해서 drop한다.\n",
    "# 아래와 비교해서 뭐가 좋을까\n",
    "def create_base_df1():\n",
    "        filt = [ele for ele in now_df_columns if ele not in rest]\n",
    "        df.drop(columns=filt, inplace=True)\n",
    "        return None\n",
    "\n",
    "# 남길 column 이름을 리스트로 받아옴.\n",
    "def create_base_df2(c_names):\n",
    "        base_df = df[c_names].copy()\n",
    "        return base_df\n",
    "\n",
    "def create_xlsx(dataframe):\n",
    "        ntm = strftime('%Y%m%d_%H%M%S', localtime())\n",
    "        cwd = os.getcwd()\n",
    "        file_path ='..\\\\output\\\\ProteinGroups_base'+ntm+'.xlsx'\n",
    "        dataframe.to_excel(excel_writer=file_path, index=False, encoding='utf-8')\n",
    "        print('message! >>> file created. '+cwd.replace('jobs','')+file_path[3:])\n",
    "        return None\n",
    "\n",
    "# *.csv 도 엑셀로 열면되기 때문에 csv가 좀 더 보편적일지도... 다시 load할 때도.\n",
    "def create_csv(dataframe):\n",
    "        ntm = strftime('%Y%m%d_%H%M%S', localtime())\n",
    "        cwd = os.getcwd()\n",
    "        file_path ='..\\\\output\\\\ProteinGroups_base'+ntm+'.csv'\n",
    "        dataframe.to_csv(path_or_buf=file_path, sep=',', index=False, encoding='utf-8')\n",
    "        print('message! >>> file created. '+cwd.replace('jobs','')+file_path[3:])\n",
    "        return None\n",
    "\n",
    "# path 만드는 class 만들기.\n",
    "# raw file에 따라서 달라져야해\n",
    "\n",
    "\n",
    "new_df = create_base_df2(rest)\n",
    "create_csv(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base 파일 생성하기.\n",
    "# 1단계로, protein groups에 대해서만 생성하고 2단계로 여러 txt 파일도 가능해야 합니다.\n",
    "# tab/comma 로 구분되는 csv, utf-8 encoding, index=False\n",
    "# 여기까지하면 예전에 작업한 pg_03_3_processing은 완료되었다 볼 수 있습니다.\n",
    "\n",
    "# pg_03_3_processing.ipynb 에서 class 참조.\n",
    "import pandas as pd\n",
    "from time import localtime, strftime\n",
    "\n",
    "class op_address():\n",
    "    # __init__ 에서 초기 설정 값 잡는게 일반적임.\n",
    "    def __init__(self, vers):\n",
    "        self.vers = vers\n",
    "        \n",
    "    def pg_address(self):\n",
    "        address = './outputs/'+txtpath[26:66]+'_proteinGroups_v'+str(self.vers)+'.txt'\n",
    "        return address\n",
    "\n",
    "    def pep_address(self):\n",
    "        address = './outputs/'+txtpath[26:66]+'_peptides_v'+str(self.vers)+'.txt'\n",
    "        return address\n",
    "    \n",
    "    def pg_address2(self):\n",
    "        tm = localtime()\n",
    "        ntm = strftime('%Y%m%d_%H%M%S', tm)\n",
    "        address = './outputs/proteinGroups_v'+str(self.vers)+'-'+ntm+'.txt'\n",
    "        return address\n",
    "    \n",
    "    def pep_address2(self):\n",
    "        tm = localtime()\n",
    "        ntm = strftime('%Y%m%d_%H%M%S', tm)\n",
    "        address = './outputs/peptides_v'+str(self.vers)+'-'+ntm+'.txt'\n",
    "        return address\n",
    "\n",
    "\n",
    "\n",
    "# Generate file: version 1\n",
    "v = op_address()\n",
    "df.to_csv(path_or_buf=v.pg_address(), sep='\\t', index=False, encoding='utf-8')\n",
    "print('message! >>> '+v.pg_address()+' added.')\n",
    "\n",
    "# df.to_excel\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ; 구분 요소 split (구버전)\n",
    "\n",
    "# Protein IDs, Best MS/MS 의 delimeter (;) 로 구분된 데이터를 나누어 첫 번째 항목을 저장합니다.\n",
    "# 해당 column 이름을 1차원 series로 저장하고, deilmeter를 기준으로 구분한 뒤,\n",
    "# 첫번째 값으로 replace 합니다.\n",
    "# split에 사용한 객체는 초기화 되어야 합니다.\n",
    "\n",
    "# (1) Protein IDs\n",
    "prot = pd.Series(df['Protein IDs'])\n",
    "for ele in prot:\n",
    "    tmp = ele.split(';')[0]\n",
    "    prot.replace(ele, tmp, inplace=True)\n",
    "print('message! >>> [Protein IDs] splitted.')\n",
    "\n",
    "# (2) Best MS/MS\n",
    "bmsms = pd.Series(df['Best MS/MS'])\n",
    "for ele in bmsms:\n",
    "    tmp = ele.split(';')[0]\n",
    "    bmsms.replace(ele, tmp, inplace=True)\n",
    "print('message! >>> [Best MS/MS] splitted.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter (구버전)\n",
    "\n",
    "# Drop: Positive value for (Potential contaminant), (Reverse), (Only identified by site)\n",
    "# Drop : 1 (Razor + unique peptides)\n",
    "\n",
    "# Drop: Positive value for (Potential contaminant), and drop the column\n",
    "len_tmp = len(df[df['Potential contaminant'] == '+'])\n",
    "df.drop(df[df['Potential contaminant'] == '+'].index, inplace = True)\n",
    "df.drop(columns=['Potential contaminant'], inplace=True)\n",
    "print('message! >>> '+str(len_tmp)+' Potential contaminant entries were dropped')\n",
    "\n",
    "\n",
    "# Drop: Positive value for (Reverse), and drop the column\n",
    "len_tmp = len(df[df['Reverse'] == '+'])\n",
    "df.drop(df[df['Reverse'] == '+'].index, inplace = True)\n",
    "df.drop(columns=['Reverse'], inplace=True)\n",
    "print('message! >>> '+str(len_tmp)+' [Reverse entries] were dropped')\n",
    "\n",
    "\n",
    "# Drop: Positive value for (Only identified by site), and drop the column\n",
    "len_tmp = len(df[df['Only identified by site'] == '+'])\n",
    "df.drop(df[df['Only identified by site'] == '+'].index, inplace = True)\n",
    "df.drop(columns=['Only identified by site'], inplace=True)\n",
    "print('message! >>> '+str(len_tmp)+' [Only identified by site] entries were dropped')\n",
    "\n",
    "\n",
    "# Drop: (Razor + unique peptides = 1), and drop the column\n",
    "len_tmp = len(df[df['Razor + unique peptides'] == 1])\n",
    "df.drop(df[df['Razor + unique peptides'] == 1].index, inplace = True)\n",
    "df.drop(columns=['Razor + unique peptides'], inplace=True)\n",
    "print('message! >>> '+str(len_tmp)+' [Razor + uniqe peptides = 1] (%.1f%%) entries were dropped' %(100*len_tmp/(len(df)+len_tmp)))\n",
    "\n",
    "\n",
    "# Monitor: # of remained entries\n",
    "print('message! >>> '+str(len(df))+' entries were remained')\n",
    "\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18c61dc58fc59d7f173ba01a525b9eea34bc3a598b0d44c34b84d235d14763dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
