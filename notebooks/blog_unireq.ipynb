{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the API that requests ID_mapping job for Uniprot_Accession_ID.\n",
    "\n",
    "Orignial codes from: <https://rest.uniprot.org/help/id_mapping>.\n",
    "(Page last modified: Fri. Oct 14, 2022)\n",
    "\n",
    "Thanks to Uniprot Team.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import zlib\n",
    "import csv\n",
    "import pandas as pd\n",
    "from xml.etree import ElementTree\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "\n",
    "POLLING_INTERVAL = 3\n",
    "API_URL = \"https://rest.uniprot.org\"\n",
    "\n",
    "\n",
    "retries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "\n",
    "def check_response(response):\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError:\n",
    "        print(response.json())\n",
    "        raise\n",
    "\n",
    "\n",
    "def submit_id_mapping(from_db, to_db, ids):\n",
    "    request = requests.post(\n",
    "        f\"{API_URL}/idmapping/run\",\n",
    "        data={\"from\": from_db, \"to\": to_db, \"ids\": \",\".join(ids)},\n",
    "    )\n",
    "    check_response(request)\n",
    "    return request.json()[\"jobId\"]\n",
    "\n",
    "\n",
    "def get_next_link(headers):\n",
    "    re_next_link = re.compile(r'<(.+)>; rel=\"next\"')\n",
    "    if \"Link\" in headers:\n",
    "        match = re_next_link.match(headers[\"Link\"])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "\n",
    "\n",
    "def check_id_mapping_results_ready(job_id):\n",
    "    while True:\n",
    "        request = session.get(f\"{API_URL}/idmapping/status/{job_id}\")\n",
    "        check_response(request)\n",
    "        j = request.json()\n",
    "        if \"jobStatus\" in j:\n",
    "            if j[\"jobStatus\"] == \"RUNNING\":\n",
    "                print(f\"Retrying in {POLLING_INTERVAL}s\")\n",
    "                time.sleep(POLLING_INTERVAL)\n",
    "            else:\n",
    "                raise Exception(j[\"jobStatus\"])\n",
    "        else:\n",
    "            return bool(j[\"results\"] or j[\"failedIds\"])\n",
    "\n",
    "\n",
    "def get_batch(batch_response, file_format, compressed):\n",
    "    batch_url = get_next_link(batch_response.headers)\n",
    "    while batch_url:\n",
    "        batch_response = session.get(batch_url)\n",
    "        batch_response.raise_for_status()\n",
    "        yield decode_results(batch_response, file_format, compressed)\n",
    "        batch_url = get_next_link(batch_response.headers)\n",
    "\n",
    "\n",
    "def combine_batches(all_results, batch_results, file_format):\n",
    "    if file_format == \"json\":\n",
    "        for key in (\"results\", \"failedIds\"):\n",
    "            if key in batch_results and batch_results[key]:\n",
    "                all_results[key] += batch_results[key]\n",
    "    elif file_format == \"tsv\":\n",
    "        return all_results + batch_results[1:]\n",
    "    else:\n",
    "        return all_results + batch_results\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def get_id_mapping_results_link(job_id):\n",
    "    url = f\"{API_URL}/idmapping/details/{job_id}\"\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    return request.json()[\"redirectURL\"]\n",
    "\n",
    "\n",
    "def decode_results(response, file_format, compressed):\n",
    "    if compressed:\n",
    "        decompressed = zlib.decompress(response.content, 16 + zlib.MAX_WBITS)\n",
    "        if file_format == \"json\":\n",
    "            j = json.loads(decompressed.decode(\"utf-8\"))\n",
    "            return j\n",
    "        elif file_format == \"tsv\":\n",
    "            return [line for line in decompressed.decode(\"utf-8\").split(\"\\n\") if line]\n",
    "        elif file_format == \"xlsx\":\n",
    "            return [decompressed]\n",
    "        elif file_format == \"xml\":\n",
    "            return [decompressed.decode(\"utf-8\")]\n",
    "        else:\n",
    "            return decompressed.decode(\"utf-8\")\n",
    "    elif file_format == \"json\":\n",
    "        return response.json()\n",
    "    elif file_format == \"tsv\":\n",
    "        return [line for line in response.text.split(\"\\n\") if line]\n",
    "    elif file_format == \"xlsx\":\n",
    "        return [response.content]\n",
    "    elif file_format == \"xml\":\n",
    "        return [response.text]\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def get_xml_namespace(element):\n",
    "    m = re.match(r\"\\{(.*)\\}\", element.tag)\n",
    "    return m.groups()[0] if m else \"\"\n",
    "\n",
    "\n",
    "def merge_xml_results(xml_results):\n",
    "    merged_root = ElementTree.fromstring(xml_results[0])\n",
    "    for result in xml_results[1:]:\n",
    "        root = ElementTree.fromstring(result)\n",
    "        for child in root.findall(\"{http://uniprot.org/uniprot}entry\"):\n",
    "            merged_root.insert(-1, child)\n",
    "    ElementTree.register_namespace(\"\", get_xml_namespace(merged_root[0]))\n",
    "    return ElementTree.tostring(merged_root, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "\n",
    "def print_progress_batches(batch_index, size, total):\n",
    "    n_fetched = min((batch_index + 1) * size, total)\n",
    "    print(f\"Fetched: {n_fetched} / {total}\")\n",
    "\n",
    "\n",
    "def get_id_mapping_results_search(url):\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    file_format = query[\"format\"][0] if \"format\" in query else \"json\"\n",
    "    if \"size\" in query:\n",
    "        size = int(query[\"size\"][0])\n",
    "    else:\n",
    "        size = 500\n",
    "        query[\"size\"] = size\n",
    "    compressed = (\n",
    "        query[\"compressed\"][0].lower() == \"true\" if \"compressed\" in query else False\n",
    "    )\n",
    "    parsed = parsed._replace(query=urlencode(query, doseq=True))\n",
    "    url = parsed.geturl()\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    results = decode_results(request, file_format, compressed)\n",
    "    total = int(request.headers[\"x-total-results\"])\n",
    "    print_progress_batches(0, size, total)\n",
    "    for i, batch in enumerate(get_batch(request, file_format, compressed), 1):\n",
    "        results = combine_batches(results, batch, file_format)\n",
    "        print_progress_batches(i, size, total)\n",
    "    if file_format == \"xml\":\n",
    "        return merge_xml_results(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_id_mapping_results_stream(url):\n",
    "    if \"/stream/\" not in url:\n",
    "        url = url.replace(\"/results/\", \"/results/stream/\")\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    file_format = query[\"format\"][0] if \"format\" in query else \"json\"\n",
    "    compressed = (\n",
    "        query[\"compressed\"][0].lower() == \"true\" if \"compressed\" in query else False\n",
    "    )\n",
    "    return decode_results(request, file_format, compressed)\n",
    "\n",
    "\n",
    "def execute(id_series):\n",
    "    job_id = submit_id_mapping(\n",
    "        from_db=\"UniProtKB_AC-ID\", to_db=\"UniProtKB\", ids=id_series\n",
    "    )\n",
    "    if check_id_mapping_results_ready(job_id):\n",
    "        link = get_id_mapping_results_link(job_id)\n",
    "        # results = get_id_mapping_results_search(link)\n",
    "        # Equivalently using the stream endpoint which is more demanding\n",
    "        # on the API and so is less stable:\n",
    "        # results = get_id_mapping_results_stream(link)\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Reviewed</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Protein names</th>\n",
       "      <th>Gene Names</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>A0FGR8</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ESYT2_HUMAN</td>\n",
       "      <td>Extended synaptotagmin-2 (E-Syt2) (Chr2Syt)</td>\n",
       "      <td>ESYT2 FAM62B KIAA1228</td>\n",
       "      <td>921</td>\n",
       "      <td>MTANRDAALSSHRHPGCAQRPRTPTFASSSQRRSAFGFDDGNFPGL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6NHR9</td>\n",
       "      <td>A6NHR9</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>SMHD1_HUMAN</td>\n",
       "      <td>Structural maintenance of chromosomes flexible...</td>\n",
       "      <td>SMCHD1 KIAA0650</td>\n",
       "      <td>2005</td>\n",
       "      <td>MAAADGGGPGGASVGTEEDGGGVGHRTVYLFDRREKESELGDRPLQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q99613</td>\n",
       "      <td>Q99613</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>EIF3C_HUMAN</td>\n",
       "      <td>Eukaryotic translation initiation factor 3 sub...</td>\n",
       "      <td>EIF3C EIF3S8</td>\n",
       "      <td>913</td>\n",
       "      <td>MSRFFTTGSDSESESSLSGEELVTKPVGGNYGKQPLLLSEDEEDTK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E9PAV3</td>\n",
       "      <td>E9PAV3</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>NACAM_HUMAN</td>\n",
       "      <td>Nascent polypeptide-associated complex subunit...</td>\n",
       "      <td>NACA</td>\n",
       "      <td>2078</td>\n",
       "      <td>MPGEATETVPATEQELPQPQAETAVLPMSSALSVTAALGQPGPTLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O00148</td>\n",
       "      <td>O00148</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>DX39A_HUMAN</td>\n",
       "      <td>ATP-dependent RNA helicase DDX39A (EC 3.6.4.13...</td>\n",
       "      <td>DDX39A DDX39</td>\n",
       "      <td>427</td>\n",
       "      <td>MAEQDVENDLLDYDEEEEPQAPQESTPAPPKKDIKGSYVSIHSSGF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     From   Entry  Reviewed   Entry Name  \\\n",
       "0  A0FGR8  A0FGR8  reviewed  ESYT2_HUMAN   \n",
       "1  A6NHR9  A6NHR9  reviewed  SMHD1_HUMAN   \n",
       "2  Q99613  Q99613  reviewed  EIF3C_HUMAN   \n",
       "3  E9PAV3  E9PAV3  reviewed  NACAM_HUMAN   \n",
       "4  O00148  O00148  reviewed  DX39A_HUMAN   \n",
       "\n",
       "                                       Protein names             Gene Names  \\\n",
       "0        Extended synaptotagmin-2 (E-Syt2) (Chr2Syt)  ESYT2 FAM62B KIAA1228   \n",
       "1  Structural maintenance of chromosomes flexible...        SMCHD1 KIAA0650   \n",
       "2  Eukaryotic translation initiation factor 3 sub...           EIF3C EIF3S8   \n",
       "3  Nascent polypeptide-associated complex subunit...                   NACA   \n",
       "4  ATP-dependent RNA helicase DDX39A (EC 3.6.4.13...           DDX39A DDX39   \n",
       "\n",
       "  Length                                           Sequence  \n",
       "0    921  MTANRDAALSSHRHPGCAQRPRTPTFASSSQRRSAFGFDDGNFPGL...  \n",
       "1   2005  MAAADGGGPGGASVGTEEDGGGVGHRTVYLFDRREKESELGDRPLQ...  \n",
       "2    913  MSRFFTTGSDSESESSLSGEELVTKPVGGNYGKQPLLLSEDEEDTK...  \n",
       "3   2078  MPGEATETVPATEQELPQPQAETAVLPMSSALSVTAALGQPGPTLP...  \n",
       "4    427  MAEQDVENDLLDYDEEEEPQAPQESTPAPPKKDIKGSYVSIHSSGF...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_frame_from_tsv_results(tsv_results):\n",
    "    reader = csv.DictReader(tsv_results, delimiter=\"\\t\", quotechar='\"')\n",
    "    return pd.DataFrame(list(reader))\n",
    "\n",
    "PRids= ['A0FGR8', 'A6NHR9', 'Q99613', 'E9PAV3', 'O00148', 'O00151', 'O15144', 'P40925']\n",
    "\n",
    "link = execute(PRids)\n",
    "\n",
    "tsv_rst = get_id_mapping_results_stream(str(link)+'?compressed=true&fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Clength%2Csequence&format=tsv')\n",
    "tmp = get_data_frame_from_tsv_results(tsv_rst)\n",
    "tmp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "596c9d63e29fcbf91eba4fd757e6e698bf89c9e1b516a0889b14eef5ff86a8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
